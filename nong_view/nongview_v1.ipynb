{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ğŸ¤– Nong-View AI ë†ì—…ì˜ìƒë¶„ì„ í”Œë«í¼ - í†µí•© ê°œë°œ ë…¸íŠ¸ë¶ v1.0\n",
    "\n",
    "**í”„ë¡œì íŠ¸ í˜„í™©**: 85% ì™„ì„± â†’ 100% MVP ëª©í‘œ  \n",
    "**í•µì‹¬ ë¸”ë¡œì»¤**: ë°ì´í„°ë² ì´ìŠ¤ í†µí•© (0% â†’ 100%)  \n",
    "**ê°œë°œ ë‚ ì§œ**: 2025-10-27  \n",
    "**ë²„ì „**: v1.0\n",
    "\n",
    "## ğŸ“‹ ê°œë°œ ì§„í–‰ ìƒí™©\n",
    "- âœ… POD ëª¨ë“ˆ (100% ì™„ì„±)\n",
    "- âœ… API êµ¬ì¡° (40% ì™„ì„±)\n",
    "- ğŸ”„ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© (ì§„í–‰ ì¤‘)\n",
    "- â³ API-POD ì—°ê²°\n",
    "- â³ í…ŒìŠ¤íŠ¸ ë° ë°°í¬\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## ğŸ”§ 1. í™˜ê²½ ì„¤ì • ë° ì˜ì¡´ì„± ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install fastapi uvicorn sqlalchemy alembic psycopg2-binary redis\n",
    "!pip install pydantic[email] python-multipart\n",
    "!pip install rasterio geopandas shapely fiona\n",
    "!pip install ultralytics torch torchvision\n",
    "!pip install pillow opencv-python numpy pandas\n",
    "!pip install python-jose[cryptography] passlib[bcrypt]\n",
    "!pip install pytest pytest-asyncio httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import asyncio\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, Union\n",
    "from pathlib import Path\n",
    "from uuid import UUID, uuid4\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# ì§€ë¦¬ì •ë³´ ì²˜ë¦¬\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, mapping\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "# ì›¹ í”„ë ˆì„ì›Œí¬\n",
    "from fastapi import FastAPI, HTTPException, Depends, UploadFile, File, BackgroundTasks\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import JSONResponse, FileResponse\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤\n",
    "from sqlalchemy import create_engine, Column, Integer, String, DateTime, Float, Text, Boolean, ForeignKey, JSON\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker, Session, relationship\n",
    "from sqlalchemy.dialects.postgresql import UUID as PG_UUID\n",
    "\n",
    "# AI/ML\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config_section",
   "metadata": {},
   "source": [
    "## âš™ï¸ 2. ì„¤ì • ë° êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¤ì • í´ë˜ìŠ¤ ì •ì˜\n",
    "class Settings:\n",
    "    \"\"\"ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •\"\"\"\n",
    "    PROJECT_NAME: str = \"Nong-View API\"\n",
    "    VERSION: str = \"1.0.0\"\n",
    "    API_V1_STR: str = \"/api/v1\"\n",
    "    ENVIRONMENT: str = \"development\"\n",
    "    DEBUG: bool = True\n",
    "    \n",
    "    # ì„œë²„ ì„¤ì •\n",
    "    HOST: str = \"127.0.0.1\"\n",
    "    PORT: int = 8000\n",
    "    \n",
    "    # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •\n",
    "    DATABASE_URL: str = \"sqlite:///./nongview_test.db\"\n",
    "    \n",
    "    # íŒŒì¼ ì €ì¥ ì„¤ì •\n",
    "    UPLOAD_PATH: str = \"./uploads\"\n",
    "    CROP_PATH: str = \"./crops\"\n",
    "    EXPORT_PATH: str = \"./exports\"\n",
    "    MAX_FILE_SIZE: int = 2 * 1024 * 1024 * 1024  # 2GB\n",
    "    \n",
    "    # AI ëª¨ë¸ ì„¤ì •\n",
    "    MODEL_PATH: str = \"./models\"\n",
    "    MAX_WORKERS: int = 4\n",
    "    \n",
    "    # ë³´ì•ˆ ì„¤ì •\n",
    "    SECRET_KEY: str = \"dev-secret-key-change-in-production\"\n",
    "    ALGORITHM: str = \"HS256\"\n",
    "    ACCESS_TOKEN_EXPIRE_MINUTES: int = 1440\n",
    "\n",
    "settings = Settings()\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "for path in [settings.UPLOAD_PATH, settings.CROP_PATH, settings.EXPORT_PATH, settings.MODEL_PATH]:\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"âœ… ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"ğŸ“ ì—…ë¡œë“œ ê²½ë¡œ: {settings.UPLOAD_PATH}\")\n",
    "print(f\"ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤: {settings.DATABASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "database_section",
   "metadata": {},
   "source": [
    "## ğŸ—„ï¸ 3. ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ ì •ì˜ (SQLAlchemy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "database_models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLAlchemy ì„¤ì •\n",
    "engine = create_engine(\n",
    "    settings.DATABASE_URL,\n",
    "    connect_args={\"check_same_thread\": False} if \"sqlite\" in settings.DATABASE_URL else {}\n",
    ")\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "Base = declarative_base()\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ ì •ì˜\n",
    "class User(Base):\n",
    "    \"\"\"ì‚¬ìš©ì ëª¨ë¸\"\"\"\n",
    "    __tablename__ = \"users\"\n",
    "    \n",
    "    id = Column(String, primary_key=True, default=lambda: str(uuid4()))\n",
    "    username = Column(String(50), unique=True, index=True, nullable=False)\n",
    "    email = Column(String(100), unique=True, index=True, nullable=False)\n",
    "    hashed_password = Column(String(100), nullable=False)\n",
    "    is_active = Column(Boolean, default=True)\n",
    "    is_superuser = Column(Boolean, default=False)\n",
    "    created_at = Column(DateTime, default=datetime.utcnow)\n",
    "    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n",
    "    \n",
    "    # ê´€ê³„\n",
    "    images = relationship(\"Image\", back_populates=\"owner\")\n",
    "    analyses = relationship(\"Analysis\", back_populates=\"owner\")\n",
    "\n",
    "\n",
    "class Image(Base):\n",
    "    \"\"\"ì´ë¯¸ì§€ ëª¨ë¸\"\"\"\n",
    "    __tablename__ = \"images\"\n",
    "    \n",
    "    id = Column(String, primary_key=True, default=lambda: str(uuid4()))\n",
    "    filename = Column(String(255), nullable=False)\n",
    "    file_path = Column(String(500), nullable=False)\n",
    "    file_size = Column(Integer, nullable=False)\n",
    "    format = Column(String(20), nullable=False)\n",
    "    status = Column(String(20), default=\"uploading\")\n",
    "    \n",
    "    # ë©”íƒ€ë°ì´í„°\n",
    "    description = Column(Text)\n",
    "    region_name = Column(String(100))\n",
    "    capture_date = Column(DateTime)\n",
    "    drone_model = Column(String(100))\n",
    "    camera_model = Column(String(100))\n",
    "    altitude = Column(Float)\n",
    "    overlap = Column(Float)\n",
    "    tags = Column(JSON)  # List[str]\n",
    "    \n",
    "    # ì§€ë¦¬ ì •ë³´\n",
    "    crs = Column(String(50))\n",
    "    bounds = Column(JSON)  # {\"minx\": float, \"miny\": float, \"maxx\": float, \"maxy\": float}\n",
    "    resolution = Column(Float)\n",
    "    width = Column(Integer)\n",
    "    height = Column(Integer)\n",
    "    bands = Column(Integer)\n",
    "    \n",
    "    # ì†Œìœ ì ë° ì‹œê°„\n",
    "    owner_id = Column(String, ForeignKey(\"users.id\"), nullable=False)\n",
    "    uploaded_at = Column(DateTime, default=datetime.utcnow)\n",
    "    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n",
    "    \n",
    "    # ê´€ê³„\n",
    "    owner = relationship(\"User\", back_populates=\"images\")\n",
    "    analyses = relationship(\"Analysis\", back_populates=\"image\")\n",
    "    crop_results = relationship(\"CropResult\", back_populates=\"image\")\n",
    "\n",
    "\n",
    "class Analysis(Base):\n",
    "    \"\"\"ë¶„ì„ ì‘ì—… ëª¨ë¸\"\"\"\n",
    "    __tablename__ = \"analyses\"\n",
    "    \n",
    "    id = Column(String, primary_key=True, default=lambda: str(uuid4()))\n",
    "    name = Column(String(200), nullable=False)\n",
    "    description = Column(Text)\n",
    "    status = Column(String(20), default=\"pending\")  # pending, running, completed, error\n",
    "    \n",
    "    # ë¶„ì„ ì„¤ì •\n",
    "    analysis_type = Column(String(50), nullable=False)  # crop, facility, landuse\n",
    "    model_version = Column(String(50))\n",
    "    confidence_threshold = Column(Float, default=0.5)\n",
    "    config = Column(JSON)  # ë¶„ì„ ì„¤ì •\n",
    "    \n",
    "    # ê²°ê³¼\n",
    "    total_detections = Column(Integer, default=0)\n",
    "    processing_time = Column(Float)\n",
    "    error_message = Column(Text)\n",
    "    result_data = Column(JSON)  # ë¶„ì„ ê²°ê³¼ ìš”ì•½\n",
    "    \n",
    "    # ê´€ê³„\n",
    "    image_id = Column(String, ForeignKey(\"images.id\"), nullable=False)\n",
    "    owner_id = Column(String, ForeignKey(\"users.id\"), nullable=False)\n",
    "    \n",
    "    # ì‹œê°„\n",
    "    created_at = Column(DateTime, default=datetime.utcnow)\n",
    "    started_at = Column(DateTime)\n",
    "    completed_at = Column(DateTime)\n",
    "    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n",
    "    \n",
    "    # ê´€ê³„\n",
    "    image = relationship(\"Image\", back_populates=\"analyses\")\n",
    "    owner = relationship(\"User\", back_populates=\"analyses\")\n",
    "    crop_results = relationship(\"CropResult\", back_populates=\"analysis\")\n",
    "    exports = relationship(\"Export\", back_populates=\"analysis\")\n",
    "\n",
    "\n",
    "class CropResult(Base):\n",
    "    \"\"\"í¬ë¡œí•‘ ê²°ê³¼ ëª¨ë¸\"\"\"\n",
    "    __tablename__ = \"crop_results\"\n",
    "    \n",
    "    id = Column(String, primary_key=True, default=lambda: str(uuid4()))\n",
    "    pnu = Column(String(19), nullable=False, index=True)  # í•„ì§€ê³ ìœ ë²ˆí˜¸\n",
    "    crop_path = Column(String(500), nullable=False)\n",
    "    crop_size = Column(Integer)\n",
    "    \n",
    "    # ì§€ì˜¤ë©”íŠ¸ë¦¬ ì •ë³´\n",
    "    geometry_type = Column(String(50))\n",
    "    area = Column(Float)\n",
    "    perimeter = Column(Float)\n",
    "    bounds = Column(JSON)\n",
    "    \n",
    "    # AI ë¶„ì„ ê²°ê³¼\n",
    "    detected_class = Column(String(50))\n",
    "    confidence = Column(Float)\n",
    "    detection_count = Column(Integer, default=0)\n",
    "    detection_data = Column(JSON)  # ìƒì„¸ ê²€ì¶œ ê²°ê³¼\n",
    "    \n",
    "    # ê´€ê³„\n",
    "    image_id = Column(String, ForeignKey(\"images.id\"), nullable=False)\n",
    "    analysis_id = Column(String, ForeignKey(\"analyses.id\"))\n",
    "    \n",
    "    # ì‹œê°„\n",
    "    created_at = Column(DateTime, default=datetime.utcnow)\n",
    "    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n",
    "    \n",
    "    # ê´€ê³„\n",
    "    image = relationship(\"Image\", back_populates=\"crop_results\")\n",
    "    analysis = relationship(\"Analysis\", back_populates=\"crop_results\")\n",
    "\n",
    "\n",
    "class Export(Base):\n",
    "    \"\"\"ë‚´ë³´ë‚´ê¸° ì‘ì—… ëª¨ë¸\"\"\"\n",
    "    __tablename__ = \"exports\"\n",
    "    \n",
    "    id = Column(String, primary_key=True, default=lambda: str(uuid4()))\n",
    "    name = Column(String(200), nullable=False)\n",
    "    export_type = Column(String(50), nullable=False)  # gpkg, geojson, csv, shapefile\n",
    "    status = Column(String(20), default=\"pending\")  # pending, processing, completed, error\n",
    "    \n",
    "    # íŒŒì¼ ì •ë³´\n",
    "    file_path = Column(String(500))\n",
    "    file_size = Column(Integer)\n",
    "    download_count = Column(Integer, default=0)\n",
    "    \n",
    "    # ë‚´ë³´ë‚´ê¸° ì„¤ì •\n",
    "    include_geometry = Column(Boolean, default=True)\n",
    "    include_metadata = Column(Boolean, default=True)\n",
    "    filter_config = Column(JSON)  # í•„í„° ì„¤ì •\n",
    "    \n",
    "    # ì˜¤ë¥˜ ì •ë³´\n",
    "    error_message = Column(Text)\n",
    "    \n",
    "    # ê´€ê³„\n",
    "    analysis_id = Column(String, ForeignKey(\"analyses.id\"), nullable=False)\n",
    "    \n",
    "    # ì‹œê°„\n",
    "    created_at = Column(DateTime, default=datetime.utcnow)\n",
    "    completed_at = Column(DateTime)\n",
    "    expires_at = Column(DateTime)  # ë‹¤ìš´ë¡œë“œ ë§Œë£Œì¼\n",
    "    \n",
    "    # ê´€ê³„\n",
    "    analysis = relationship(\"Analysis\", back_populates=\"exports\")\n",
    "\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±\n",
    "Base.metadata.create_all(bind=engine)\n",
    "\n",
    "print(\"âœ… ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"ğŸ“Š ìƒì„±ëœ í…Œì´ë¸”: {list(Base.metadata.tables.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "database_session",
   "metadata": {},
   "source": [
    "## ğŸ”— 4. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê´€ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db_session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ì˜ì¡´ì„±\n",
    "def get_db():\n",
    "    \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±\"\"\"\n",
    "    db = SessionLocal()\n",
    "    try:\n",
    "        yield db\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ìš© ì‚¬ìš©ì ìƒì„±\n",
    "def create_test_user(db: Session):\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ìš© ì‚¬ìš©ì ìƒì„±\"\"\"\n",
    "    existing_user = db.query(User).filter(User.username == \"testuser\").first()\n",
    "    if not existing_user:\n",
    "        test_user = User(\n",
    "            username=\"testuser\",\n",
    "            email=\"test@example.com\",\n",
    "            hashed_password=\"hashed_password_here\",\n",
    "            is_active=True\n",
    "        )\n",
    "        db.add(test_user)\n",
    "        db.commit()\n",
    "        db.refresh(test_user)\n",
    "        print(f\"âœ… í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ìƒì„±: {test_user.id}\")\n",
    "        return test_user\n",
    "    else:\n",
    "        print(f\"â„¹ï¸ í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ì¡´ì¬: {existing_user.id}\")\n",
    "        return existing_user\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ìƒì„±\n",
    "with SessionLocal() as db:\n",
    "    test_user = create_test_user(db)\n",
    "    \n",
    "print(\"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê´€ë¦¬ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pod_integration",
   "metadata": {},
   "source": [
    "## ğŸ”Œ 5. POD ëª¨ë“ˆ í†µí•©\n",
    "### POD1: ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pod1_data_ingestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD1: ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬ ëª¨ë“ˆ\n",
    "class DataRegistry:\n",
    "    \"\"\"ì¤‘ì•™ ë°ì´í„° ë ˆì§€ìŠ¤íŠ¸ë¦¬\"\"\"\n",
    "    \n",
    "    def __init__(self, storage_path: str):\n",
    "        self.storage_path = Path(storage_path)\n",
    "        self.storage_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def extract_image_metadata(self, file_path: Path) -> dict:\n",
    "        \"\"\"ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ\"\"\"\n",
    "        try:\n",
    "            with rasterio.open(file_path) as src:\n",
    "                bounds = {\n",
    "                    \"minx\": src.bounds.left,\n",
    "                    \"miny\": src.bounds.bottom,\n",
    "                    \"maxx\": src.bounds.right,\n",
    "                    \"maxy\": src.bounds.top\n",
    "                }\n",
    "                \n",
    "                # í•´ìƒë„ ê³„ì‚°\n",
    "                res_x = (src.bounds.right - src.bounds.left) / src.width\n",
    "                res_y = (src.bounds.top - src.bounds.bottom) / src.height\n",
    "                resolution = (res_x + res_y) / 2\n",
    "                \n",
    "                metadata = {\n",
    "                    \"crs\": str(src.crs) if src.crs else \"EPSG:5186\",\n",
    "                    \"resolution\": resolution,\n",
    "                    \"bounds\": bounds,\n",
    "                    \"width\": src.width,\n",
    "                    \"height\": src.height,\n",
    "                    \"bands\": src.count,\n",
    "                    \"format\": src.driver\n",
    "                }\n",
    "                \n",
    "                return metadata\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def save_file(self, upload_file: UploadFile) -> tuple[str, int]:\n",
    "        \"\"\"íŒŒì¼ ì €ì¥\"\"\"\n",
    "        file_id = str(uuid4())\n",
    "        file_extension = Path(upload_file.filename).suffix\n",
    "        file_path = self.storage_path / f\"{file_id}{file_extension}\"\n",
    "        \n",
    "        # íŒŒì¼ ì €ì¥\n",
    "        content = upload_file.file.read()\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(content)\n",
    "        \n",
    "        return str(file_path), len(content)\n",
    "\n",
    "# ì „ì—­ ë°ì´í„° ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¸ìŠ¤í„´ìŠ¤\n",
    "data_registry = DataRegistry(settings.UPLOAD_PATH)\n",
    "\n",
    "print(\"âœ… POD1 ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ í†µí•© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pod2_cropping",
   "metadata": {},
   "source": [
    "### POD2: í¬ë¡œí•‘ ì—”ì§„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pod2_cropping_engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD2: í¬ë¡œí•‘ ì—”ì§„\n",
    "class CroppingEngine:\n",
    "    \"\"\"ROI ì¶”ì¶œ ë° í¬ë¡œí•‘ ì—”ì§„\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: str):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def crop_by_shapes(self, image_path: str, shapefile_path: str) -> list:\n",
    "        \"\"\"Shapefile ê¸°ë°˜ ì´ë¯¸ì§€ í¬ë¡œí•‘\"\"\"\n",
    "        try:\n",
    "            # Shapefile ë¡œë“œ\n",
    "            gdf = gpd.read_file(shapefile_path)\n",
    "            \n",
    "            results = []\n",
    "            \n",
    "            with rasterio.open(image_path) as src:\n",
    "                for idx, row in gdf.iterrows():\n",
    "                    pnu = row.get('PNU', f'unknown_{idx}').zfill(19)\n",
    "                    geometry = row.geometry\n",
    "                    \n",
    "                    # í¬ë¡œí•‘ ìˆ˜í–‰\n",
    "                    try:\n",
    "                        # ì§€ì˜¤ë©”íŠ¸ë¦¬ë¡œ ë§ˆìŠ¤í‚¹\n",
    "                        out_image, out_transform = rasterio.mask.mask(\n",
    "                            src, [geometry], crop=True\n",
    "                        )\n",
    "                        \n",
    "                        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ\n",
    "                        crop_id = str(uuid4())\n",
    "                        crop_filename = f\"crop_{crop_id}_{pnu}.tif\"\n",
    "                        crop_path = self.output_dir / crop_filename\n",
    "                        \n",
    "                        # í¬ë¡­ëœ ì´ë¯¸ì§€ ì €ì¥\n",
    "                        out_meta = src.meta\n",
    "                        out_meta.update({\n",
    "                            \"driver\": \"GTiff\",\n",
    "                            \"height\": out_image.shape[1],\n",
    "                            \"width\": out_image.shape[2],\n",
    "                            \"transform\": out_transform\n",
    "                        })\n",
    "                        \n",
    "                        with rasterio.open(crop_path, \"w\", **out_meta) as dest:\n",
    "                            dest.write(out_image)\n",
    "                        \n",
    "                        # ê²°ê³¼ ì •ë³´\n",
    "                        result = {\n",
    "                            \"crop_id\": crop_id,\n",
    "                            \"pnu\": pnu,\n",
    "                            \"crop_path\": str(crop_path),\n",
    "                            \"crop_size\": crop_path.stat().st_size,\n",
    "                            \"geometry_type\": geometry.geom_type,\n",
    "                            \"area\": geometry.area,\n",
    "                            \"perimeter\": geometry.length,\n",
    "                            \"bounds\": {\n",
    "                                \"minx\": geometry.bounds[0],\n",
    "                                \"miny\": geometry.bounds[1],\n",
    "                                \"maxx\": geometry.bounds[2],\n",
    "                                \"maxy\": geometry.bounds[3]\n",
    "                            }\n",
    "                        }\n",
    "                        \n",
    "                        results.append(result)\n",
    "                        logger.info(f\"í¬ë¡œí•‘ ì™„ë£Œ: {pnu}\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"í¬ë¡œí•‘ ì‹¤íŒ¨ - PNU {pnu}: {e}\")\n",
    "                        continue\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"í¬ë¡œí•‘ ì—”ì§„ ì˜¤ë¥˜: {e}\")\n",
    "            raise\n",
    "\n",
    "# ì „ì—­ í¬ë¡œí•‘ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤\n",
    "cropping_engine = CroppingEngine(settings.CROP_PATH)\n",
    "\n",
    "print(\"âœ… POD2 í¬ë¡œí•‘ ì—”ì§„ í†µí•© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pod4_ai",
   "metadata": {},
   "source": [
    "### POD4: AI ì¶”ë¡  ì—”ì§„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pod4_ai_engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD4: AI ì¶”ë¡  ì—”ì§„\n",
    "class AIInferenceEngine:\n",
    "    \"\"\"YOLOv11 ê¸°ë°˜ AI ì¶”ë¡  ì—”ì§„\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        logger.info(f\"AI ì—”ì§„ ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}\")\n",
    "        \n",
    "        # í´ë˜ìŠ¤ ë§¤í•‘\n",
    "        self.class_mappings = {\n",
    "            'crop': {\n",
    "                0: 'IRG',      # ì´íƒˆë¦¬ì•ˆ ë¼ì´ê·¸ë¼ìŠ¤\n",
    "                1: 'BARLEY',   # ë³´ë¦¬\n",
    "                2: 'WHEAT',    # ë°€\n",
    "                3: 'CORN_SILAGE',  # ì˜¥ìˆ˜ìˆ˜ì‚¬ì¼ë¦¬ì§€\n",
    "                4: 'HAY',      # ê±´ì´ˆ\n",
    "                5: 'UNKNOWN'   # ë¯¸ë¶„ë¥˜\n",
    "            },\n",
    "            'facility': {\n",
    "                0: 'GREENHOUSE_SINGLE',  # ë‹¨ë™ ë¹„ë‹í•˜ìš°ìŠ¤\n",
    "                1: 'GREENHOUSE_MULTI',   # ì—°ë™ ë¹„ë‹í•˜ìš°ìŠ¤\n",
    "                2: 'STORAGE',            # ì €ì¥ì‹œì„¤\n",
    "                3: 'LIVESTOCK',          # ì¶•ì‚¬\n",
    "                4: 'SILO',              # ì‚¬ì¼ë¡œ\n",
    "                5: 'UNKNOWN'            # ë¯¸ë¶„ë¥˜\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def load_model(self, model_type: str, model_path: str = None):\n",
    "        \"\"\"YOLO ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "        try:\n",
    "            if model_path and Path(model_path).exists():\n",
    "                model = YOLO(model_path)\n",
    "            else:\n",
    "                # ê¸°ë³¸ YOLOv8 ëª¨ë¸ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)\n",
    "                model = YOLO('yolov8n.pt')\n",
    "                logger.warning(f\"ì‚¬ìš©ì ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {model_type}\")\n",
    "            \n",
    "            self.models[model_type] = model\n",
    "            logger.info(f\"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_type}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - {model_type}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def predict(self, image_path: str, model_type: str, confidence: float = 0.5) -> dict:\n",
    "        \"\"\"ì´ë¯¸ì§€ ì˜ˆì¸¡ ìˆ˜í–‰\"\"\"\n",
    "        try:\n",
    "            if model_type not in self.models:\n",
    "                raise ValueError(f\"ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ: {model_type}\")\n",
    "            \n",
    "            model = self.models[model_type]\n",
    "            \n",
    "            # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "            results = model(image_path, conf=confidence, device=self.device)\n",
    "            \n",
    "            detections = []\n",
    "            \n",
    "            for result in results:\n",
    "                boxes = result.boxes\n",
    "                if boxes is not None:\n",
    "                    for box in boxes:\n",
    "                        # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ\n",
    "                        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                        confidence_score = box.conf[0].item()\n",
    "                        class_id = int(box.cls[0].item())\n",
    "                        \n",
    "                        # í´ë˜ìŠ¤ ì´ë¦„ ë§¤í•‘\n",
    "                        class_name = self.class_mappings.get(model_type, {}).get(\n",
    "                            class_id, f\"class_{class_id}\"\n",
    "                        )\n",
    "                        \n",
    "                        detection = {\n",
    "                            \"class_id\": class_id,\n",
    "                            \"class_name\": class_name,\n",
    "                            \"confidence\": confidence_score,\n",
    "                            \"bbox\": [x1, y1, x2, y2],\n",
    "                            \"area\": (x2 - x1) * (y2 - y1)\n",
    "                        }\n",
    "                        \n",
    "                        detections.append(detection)\n",
    "            \n",
    "            return {\n",
    "                \"detections\": detections,\n",
    "                \"detection_count\": len(detections),\n",
    "                \"model_type\": model_type,\n",
    "                \"confidence_threshold\": confidence\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì˜ˆì¸¡ ì‹¤íŒ¨: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def predict_batch(self, image_paths: list, model_type: str, confidence: float = 0.5) -> list:\n",
    "        \"\"\"ë°°ì¹˜ ì˜ˆì¸¡ ìˆ˜í–‰\"\"\"\n",
    "        results = []\n",
    "        for image_path in image_paths:\n",
    "            try:\n",
    "                result = self.predict(image_path, model_type, confidence)\n",
    "                result['image_path'] = image_path\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"ë°°ì¹˜ ì˜ˆì¸¡ ì‹¤íŒ¨ - {image_path}: {e}\")\n",
    "                results.append({\n",
    "                    'image_path': image_path,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# ì „ì—­ AI ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤\n",
    "ai_engine = AIInferenceEngine()\n",
    "\n",
    "# ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ (í…ŒìŠ¤íŠ¸ìš©)\n",
    "try:\n",
    "    ai_engine.load_model('crop')\n",
    "    ai_engine.load_model('facility')\n",
    "    print(\"âœ… POD4 AI ì¶”ë¡  ì—”ì§„ í†µí•© ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ê¸°ë³¸ YOLO ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api_schemas",
   "metadata": {},
   "source": [
    "## ğŸ“‹ 6. API ìŠ¤í‚¤ë§ˆ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "api_schemas_definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API ì‘ë‹µ ìŠ¤í‚¤ë§ˆ\n",
    "class APIResponse(BaseModel):\n",
    "    \"\"\"ê¸°ë³¸ API ì‘ë‹µ\"\"\"\n",
    "    success: bool = True\n",
    "    message: str = \"\"\n",
    "    data: Optional[Any] = None\n",
    "    error: Optional[str] = None\n",
    "\n",
    "# ì´ë¯¸ì§€ ê´€ë ¨ ìŠ¤í‚¤ë§ˆ\n",
    "class ImageUploadRequest(BaseModel):\n",
    "    \"\"\"ì´ë¯¸ì§€ ì—…ë¡œë“œ ìš”ì²­\"\"\"\n",
    "    description: Optional[str] = None\n",
    "    region_name: Optional[str] = None\n",
    "    tags: List[str] = []\n",
    "\n",
    "class ImageResponse(BaseModel):\n",
    "    \"\"\"ì´ë¯¸ì§€ ì‘ë‹µ\"\"\"\n",
    "    id: str\n",
    "    filename: str\n",
    "    file_path: str\n",
    "    file_size: int\n",
    "    status: str\n",
    "    format: str\n",
    "    description: Optional[str] = None\n",
    "    region_name: Optional[str] = None\n",
    "    tags: List[str] = []\n",
    "    metadata: Optional[dict] = None\n",
    "    uploaded_at: datetime\n",
    "    updated_at: datetime\n",
    "\n",
    "# ë¶„ì„ ê´€ë ¨ ìŠ¤í‚¤ë§ˆ\n",
    "class AnalysisRequest(BaseModel):\n",
    "    \"\"\"ë¶„ì„ ìš”ì²­\"\"\"\n",
    "    name: str\n",
    "    description: Optional[str] = None\n",
    "    analysis_type: str  # crop, facility, landuse\n",
    "    confidence_threshold: float = Field(0.5, ge=0.1, le=1.0)\n",
    "    shapefile_path: Optional[str] = None  # í¬ë¡œí•‘ìš© Shapefile\n",
    "\n",
    "class AnalysisResponse(BaseModel):\n",
    "    \"\"\"ë¶„ì„ ì‘ë‹µ\"\"\"\n",
    "    id: str\n",
    "    name: str\n",
    "    description: Optional[str] = None\n",
    "    status: str\n",
    "    analysis_type: str\n",
    "    confidence_threshold: float\n",
    "    total_detections: int = 0\n",
    "    processing_time: Optional[float] = None\n",
    "    error_message: Optional[str] = None\n",
    "    created_at: datetime\n",
    "    started_at: Optional[datetime] = None\n",
    "    completed_at: Optional[datetime] = None\n",
    "\n",
    "# í¬ë¡­ ê²°ê³¼ ìŠ¤í‚¤ë§ˆ\n",
    "class CropResultResponse(BaseModel):\n",
    "    \"\"\"í¬ë¡­ ê²°ê³¼ ì‘ë‹µ\"\"\"\n",
    "    id: str\n",
    "    pnu: str\n",
    "    crop_path: str\n",
    "    crop_size: int\n",
    "    geometry_type: str\n",
    "    area: float\n",
    "    detected_class: Optional[str] = None\n",
    "    confidence: Optional[float] = None\n",
    "    detection_count: int = 0\n",
    "    created_at: datetime\n",
    "\n",
    "print(\"âœ… API ìŠ¤í‚¤ë§ˆ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fastapi_app",
   "metadata": {},
   "source": [
    "## ğŸš€ 7. FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fastapi_application",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±\n",
    "app = FastAPI(\n",
    "    title=settings.PROJECT_NAME,\n",
    "    description=\"AI ê¸°ë°˜ ë†ì—… ì˜ìƒ ë¶„ì„ í”Œë«í¼ API\",\n",
    "    version=settings.VERSION,\n",
    "    docs_url=\"/api/docs\",\n",
    "    redoc_url=\"/api/redoc\"\n",
    ")\n",
    "\n",
    "# CORS ë¯¸ë“¤ì›¨ì–´\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# í—¬ìŠ¤ ì²´í¬\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸\"\"\"\n",
    "    return APIResponse(\n",
    "        success=True,\n",
    "        message=\"ì„œë¹„ìŠ¤ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤\",\n",
    "        data={\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"version\": settings.VERSION,\n",
    "            \"environment\": settings.ENVIRONMENT\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"âœ… FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "images_api",
   "metadata": {},
   "source": [
    "## ğŸ“¸ 8. Images API êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "images_api_implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images API ì—”ë“œí¬ì¸íŠ¸\n",
    "@app.post(\"/api/v1/images/upload\", response_model=APIResponse)\n",
    "async def upload_image(\n",
    "    file: UploadFile = File(...),\n",
    "    description: str = None,\n",
    "    region_name: str = None,\n",
    "    db: Session = Depends(get_db)\n",
    "):\n",
    "    \"\"\"ì´ë¯¸ì§€ ì—…ë¡œë“œ\"\"\"\n",
    "    try:\n",
    "        # íŒŒì¼ í™•ì¥ì ê²€ì¦\n",
    "        allowed_extensions = ['.tif', '.tiff', '.jp2']\n",
    "        file_extension = Path(file.filename).suffix.lower()\n",
    "        if file_extension not in allowed_extensions:\n",
    "            raise HTTPException(\n",
    "                status_code=400,\n",
    "                detail=f\"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_extension}\"\n",
    "            )\n",
    "        \n",
    "        # íŒŒì¼ ì €ì¥\n",
    "        file_path, file_size = data_registry.save_file(file)\n",
    "        \n",
    "        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ\n",
    "        try:\n",
    "            metadata = data_registry.extract_image_metadata(Path(file_path))\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "            metadata = {}\n",
    "        \n",
    "        # í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ê°€ì ¸ì˜¤ê¸°\n",
    "        test_user = db.query(User).filter(User.username == \"testuser\").first()\n",
    "        if not test_user:\n",
    "            raise HTTPException(status_code=404, detail=\"í…ŒìŠ¤íŠ¸ ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        \n",
    "        # ë°ì´í„°ë² ì´ìŠ¤ì— ì´ë¯¸ì§€ ì •ë³´ ì €ì¥\n",
    "        db_image = Image(\n",
    "            filename=file.filename,\n",
    "            file_path=file_path,\n",
    "            file_size=file_size,\n",
    "            format=file_extension.replace('.', ''),\n",
    "            status=\"ready\",\n",
    "            description=description,\n",
    "            region_name=region_name,\n",
    "            owner_id=test_user.id,\n",
    "            crs=metadata.get('crs'),\n",
    "            bounds=metadata.get('bounds'),\n",
    "            resolution=metadata.get('resolution'),\n",
    "            width=metadata.get('width'),\n",
    "            height=metadata.get('height'),\n",
    "            bands=metadata.get('bands')\n",
    "        )\n",
    "        \n",
    "        db.add(db_image)\n",
    "        db.commit()\n",
    "        db.refresh(db_image)\n",
    "        \n",
    "        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±\n",
    "        response_data = ImageResponse(\n",
    "            id=db_image.id,\n",
    "            filename=db_image.filename,\n",
    "            file_path=db_image.file_path,\n",
    "            file_size=db_image.file_size,\n",
    "            status=db_image.status,\n",
    "            format=db_image.format,\n",
    "            description=db_image.description,\n",
    "            region_name=db_image.region_name,\n",
    "            tags=[],\n",
    "            metadata=metadata,\n",
    "            uploaded_at=db_image.uploaded_at,\n",
    "            updated_at=db_image.updated_at\n",
    "        )\n",
    "        \n",
    "        return APIResponse(\n",
    "            success=True,\n",
    "            message=\"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ\",\n",
    "            data=response_data.dict()\n",
    "        )\n",
    "        \n",
    "    except HTTPException:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "\n",
    "@app.get(\"/api/v1/images\", response_model=APIResponse)\n",
    "async def list_images(db: Session = Depends(get_db)):\n",
    "    \"\"\"ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ\"\"\"\n",
    "    try:\n",
    "        images = db.query(Image).all()\n",
    "        \n",
    "        image_list = []\n",
    "        for img in images:\n",
    "            image_data = ImageResponse(\n",
    "                id=img.id,\n",
    "                filename=img.filename,\n",
    "                file_path=img.file_path,\n",
    "                file_size=img.file_size,\n",
    "                status=img.status,\n",
    "                format=img.format,\n",
    "                description=img.description,\n",
    "                region_name=img.region_name,\n",
    "                tags=img.tags or [],\n",
    "                uploaded_at=img.uploaded_at,\n",
    "                updated_at=img.updated_at\n",
    "            )\n",
    "            image_list.append(image_data.dict())\n",
    "        \n",
    "        return APIResponse(\n",
    "            success=True,\n",
    "            message=f\"{len(image_list)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤\",\n",
    "            data={\"images\": image_list, \"total\": len(image_list)}\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "\n",
    "@app.get(\"/api/v1/images/{image_id}\", response_model=APIResponse)\n",
    "async def get_image(image_id: str, db: Session = Depends(get_db)):\n",
    "    \"\"\"ì´ë¯¸ì§€ ìƒì„¸ ì¡°íšŒ\"\"\"\n",
    "    try:\n",
    "        image = db.query(Image).filter(Image.id == image_id).first()\n",
    "        if not image:\n",
    "            raise HTTPException(status_code=404, detail=\"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        \n",
    "        image_data = ImageResponse(\n",
    "            id=image.id,\n",
    "            filename=image.filename,\n",
    "            file_path=image.file_path,\n",
    "            file_size=image.file_size,\n",
    "            status=image.status,\n",
    "            format=image.format,\n",
    "            description=image.description,\n",
    "            region_name=image.region_name,\n",
    "            tags=image.tags or [],\n",
    "            metadata={\n",
    "                \"crs\": image.crs,\n",
    "                \"bounds\": image.bounds,\n",
    "                \"resolution\": image.resolution,\n",
    "                \"width\": image.width,\n",
    "                \"height\": image.height,\n",
    "                \"bands\": image.bands\n",
    "            },\n",
    "            uploaded_at=image.uploaded_at,\n",
    "            updated_at=image.updated_at\n",
    "        )\n",
    "        \n",
    "        return APIResponse(\n",
    "            success=True,\n",
    "            message=\"ì´ë¯¸ì§€ ì¡°íšŒ ì™„ë£Œ\",\n",
    "            data=image_data.dict()\n",
    "        )\n",
    "        \n",
    "    except HTTPException:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ì´ë¯¸ì§€ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"ì´ë¯¸ì§€ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "print(\"âœ… Images API êµ¬í˜„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis_api",
   "metadata": {},
   "source": [
    "## ğŸ”¬ 9. Analysis API êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis_api_implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis API ì—”ë“œí¬ì¸íŠ¸\n",
    "@app.post(\"/api/v1/analyses\", response_model=APIResponse)\n",
    "async def create_analysis(\n",
    "    image_id: str,\n",
    "    request: AnalysisRequest,\n",
    "    background_tasks: BackgroundTasks,\n",
    "    db: Session = Depends(get_db)\n",
    "):\n",
    "    \"\"\"ë¶„ì„ ì‘ì—… ìƒì„±\"\"\"\n",
    "    try:\n",
    "        # ì´ë¯¸ì§€ ì¡´ì¬ í™•ì¸\n",
    "        image = db.query(Image).filter(Image.id == image_id).first()\n",
    "        if not image:\n",
    "            raise HTTPException(status_code=404, detail=\"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        \n",
    "        # í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ê°€ì ¸ì˜¤ê¸°\n",
    "        test_user = db.query(User).filter(User.username == \"testuser\").first()\n",
    "        if not test_user:\n",
    "            raise HTTPException(status_code=404, detail=\"í…ŒìŠ¤íŠ¸ ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        \n",
    "        # ë¶„ì„ ì‘ì—… ìƒì„±\n",
    "        analysis = Analysis(\n",
    "            name=request.name,\n",
    "            description=request.description,\n",
    "            analysis_type=request.analysis_type,\n",
    "            confidence_threshold=request.confidence_threshold,\n",
    "            image_id=image_id,\n",
    "            owner_id=test_user.id,\n",
    "            status=\"pending\"\n",
    "        )\n",
    "        \n",
    "        db.add(analysis)\n",
    "        db.commit()\n",
    "        db.refresh(analysis)\n",
    "        \n",
    "        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¶„ì„ ì‹¤í–‰\n",
    "        background_tasks.add_task(\n",
    "            run_analysis_task,\n",
    "            analysis.id,\n",
    "            image.file_path,\n",
    "            request.analysis_type,\n",
    "            request.confidence_threshold,\n",
    "            request.shapefile_path\n",
    "        )\n",
    "        \n",
    "        response_data = AnalysisResponse(\n",
    "            id=analysis.id,\n",
    "            name=analysis.name,\n",
    "            description=analysis.description,\n",
    "            status=analysis.status,\n",
    "            analysis_type=analysis.analysis_type,\n",
    "            confidence_threshold=analysis.confidence_threshold,\n",
    "            created_at=analysis.created_at\n",
    "        )\n",
    "        \n",
    "        return APIResponse(\n",
    "            success=True,\n",
    "            message=\"ë¶„ì„ ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤\",\n",
    "            data=response_data.dict()\n",
    "        )\n",
    "        \n",
    "    except HTTPException:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ë¶„ì„ ì‘ì—… ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"ë¶„ì„ ì‘ì—… ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "\n",
    "def run_analysis_task(\n",
    "    analysis_id: str,\n",
    "    image_path: str,\n",
    "    analysis_type: str,\n",
    "    confidence_threshold: float,\n",
    "    shapefile_path: str = None\n",
    "):\n",
    "    \"\"\"ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì‘ì—… ì‹¤í–‰\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with SessionLocal() as db:\n",
    "        try:\n",
    "            # ë¶„ì„ ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "            analysis = db.query(Analysis).filter(Analysis.id == analysis_id).first()\n",
    "            if not analysis:\n",
    "                logger.error(f\"ë¶„ì„ ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {analysis_id}\")\n",
    "                return\n",
    "            \n",
    "            analysis.status = \"running\"\n",
    "            analysis.started_at = datetime.utcnow()\n",
    "            db.commit()\n",
    "            \n",
    "            logger.info(f\"ë¶„ì„ ì‹œì‘: {analysis_id} - {analysis_type}\")\n",
    "            \n",
    "            # 1. í¬ë¡œí•‘ (Shapefileì´ ì œê³µëœ ê²½ìš°)\n",
    "            crop_results = []\n",
    "            if shapefile_path and Path(shapefile_path).exists():\n",
    "                logger.info(\"í¬ë¡œí•‘ ìˆ˜í–‰ ì¤‘...\")\n",
    "                crop_data = cropping_engine.crop_by_shapes(image_path, shapefile_path)\n",
    "                \n",
    "                # í¬ë¡­ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥\n",
    "                for crop_info in crop_data:\n",
    "                    crop_result = CropResult(\n",
    "                        pnu=crop_info[\"pnu\"],\n",
    "                        crop_path=crop_info[\"crop_path\"],\n",
    "                        crop_size=crop_info[\"crop_size\"],\n",
    "                        geometry_type=crop_info[\"geometry_type\"],\n",
    "                        area=crop_info[\"area\"],\n",
    "                        perimeter=crop_info[\"perimeter\"],\n",
    "                        bounds=crop_info[\"bounds\"],\n",
    "                        image_id=analysis.image_id,\n",
    "                        analysis_id=analysis_id\n",
    "                    )\n",
    "                    db.add(crop_result)\n",
    "                    crop_results.append(crop_result)\n",
    "                \n",
    "                db.commit()\n",
    "                logger.info(f\"í¬ë¡œí•‘ ì™„ë£Œ: {len(crop_results)}ê°œ ê²°ê³¼\")\n",
    "            \n",
    "            # 2. AI ì¶”ë¡  ì‹¤í–‰\n",
    "            total_detections = 0\n",
    "            \n",
    "            if crop_results:\n",
    "                # í¬ë¡­ëœ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•´ AI ì¶”ë¡ \n",
    "                crop_paths = [cr.crop_path for cr in crop_results]\n",
    "                prediction_results = ai_engine.predict_batch(\n",
    "                    crop_paths, analysis_type, confidence_threshold\n",
    "                )\n",
    "                \n",
    "                # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í¬ë¡­ ê²°ê³¼ì— ì—…ë°ì´íŠ¸\n",
    "                for i, crop_result in enumerate(crop_results):\n",
    "                    if i < len(prediction_results):\n",
    "                        pred_result = prediction_results[i]\n",
    "                        if 'error' not in pred_result:\n",
    "                            detections = pred_result.get('detections', [])\n",
    "                            if detections:\n",
    "                                # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ í´ë˜ìŠ¤ ì„ íƒ\n",
    "                                best_detection = max(detections, key=lambda x: x['confidence'])\n",
    "                                crop_result.detected_class = best_detection['class_name']\n",
    "                                crop_result.confidence = best_detection['confidence']\n",
    "                            \n",
    "                            crop_result.detection_count = len(detections)\n",
    "                            crop_result.detection_data = pred_result\n",
    "                            total_detections += len(detections)\n",
    "                \n",
    "                db.commit()\n",
    "            else:\n",
    "                # ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•´ AI ì¶”ë¡ \n",
    "                prediction_result = ai_engine.predict(\n",
    "                    image_path, analysis_type, confidence_threshold\n",
    "                )\n",
    "                total_detections = prediction_result.get('detection_count', 0)\n",
    "                analysis.result_data = prediction_result\n",
    "            \n",
    "            # ë¶„ì„ ì™„ë£Œ ì²˜ë¦¬\n",
    "            processing_time = time.time() - start_time\n",
    "            analysis.status = \"completed\"\n",
    "            analysis.completed_at = datetime.utcnow()\n",
    "            analysis.total_detections = total_detections\n",
    "            analysis.processing_time = processing_time\n",
    "            \n",
    "            db.commit()\n",
    "            \n",
    "            logger.info(f\"ë¶„ì„ ì™„ë£Œ: {analysis_id} - {total_detections}ê°œ ê²€ì¶œ, {processing_time:.2f}ì´ˆ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            # ì—ëŸ¬ ì²˜ë¦¬\n",
    "            logger.error(f\"ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n",
    "            analysis.status = \"error\"\n",
    "            analysis.error_message = str(e)\n",
    "            analysis.completed_at = datetime.utcnow()\n",
    "            db.commit()\n",
    "\n",
    "\n",
    "@app.get(\"/api/v1/analyses\", response_model=APIResponse)\n",
    "async def list_analyses(db: Session = Depends(get_db)):\n",
    "    \"\"\"ë¶„ì„ ëª©ë¡ ì¡°íšŒ\"\"\"\n",
    "    try:\n",
    "        analyses = db.query(Analysis).all()\n",
    "        \n",
    "        analysis_list = []\n",
    "        for analysis in analyses:\n",
    "            analysis_data = AnalysisResponse(\n",
    "                id=analysis.id,\n",
    "                name=analysis.name,\n",
    "                description=analysis.description,\n",
    "                status=analysis.status,\n",
    "                analysis_type=analysis.analysis_type,\n",
    "                confidence_threshold=analysis.confidence_threshold,\n",
    "                total_detections=analysis.total_detections,\n",
    "                processing_time=analysis.processing_time,\n",
    "                error_message=analysis.error_message,\n",
    "                created_at=analysis.created_at,\n",
    "                started_at=analysis.started_at,\n",
    "                completed_at=analysis.completed_at\n",
    "            )\n",
    "            analysis_list.append(analysis_data.dict())\n",
    "        \n",
    "        return APIResponse(\n",
    "            success=True,\n",
    "            message=f\"{len(analysis_list)}ê°œì˜ ë¶„ì„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤\",\n",
    "            data={\"analyses\": analysis_list, \"total\": len(analysis_list)}\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"ë¶„ì„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"ë¶„ì„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "\n",
    "@app.get(\"/api/v1/analyses/{analysis_id}\", response_model=APIResponse)\n",
    "async def get_analysis(analysis_id: str, db: Session = Depends(get_db)):\n",
    "    \"\"\"ë¶„ì„ ìƒì„¸ ì¡°íšŒ\"\"\"\n",
    "    try:\n",
    "        analysis = db.query(Analysis).filter(Analysis.id == analysis_id).first()\n",
    "        if not analysis:\n",
    "            raise HTTPException(status_code=404, detail=\"ë¶„ì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        \n",
    "        # í¬ë¡­ ê²°ê³¼ë„ í•¨ê»˜ ì¡°íšŒ\n",
    "        crop_results = db.query(CropResult).filter(CropResult.analysis_id == analysis_id).all()\n",
    "        \n",
    "        crop_result_list = []\n",
    "        for crop in crop_results:\n",
    "            crop_data = CropResultResponse(\n",
    "                id=crop.id,\n",
    "                pnu=crop.pnu,\n",
    "                crop_path=crop.crop_path,\n",
    "                crop_size=crop.crop_size,\n",
    "                geometry_type=crop.geometry_type,\n",
    "                area=crop.area,\n",
    "                detected_class=crop.detected_class,\n",
    "                confidence=crop.confidence,\n",
    "                detection_count=crop.detection_count,\n",
    "                created_at=crop.created_at\n",
    "            )\n",
    "            crop_result_list.append(crop_data.dict())\n",
    "        \n",
    "        analysis_data = AnalysisResponse(\n",
    "            id=analysis.id,\n",
    "            name=analysis.name,\n",
    "            description=analysis.description,\n",
    "            status=analysis.status,\n",
    "            analysis_type=analysis.analysis_type,\n",
    "            confidence_threshold=analysis.confidence_threshold,\n",
    "            total_detections=analysis.total_detections,\n",
    "            processing_time=analysis.processing_time,\n",
    "            error_message=analysis.error_message,\n",
    "            created_at=analysis.created_at,\n",
    "            started_at=analysis.started_at,\n",
    "            completed_at=analysis.completed_at\n",
    "        )\n",
    "        \n",
    "        return APIResponse(\n",
    "            success=True,\n",
    "            message=\"ë¶„ì„ ì¡°íšŒ ì™„ë£Œ\",\n",
    "            data={\n",
    "                \"analysis\": analysis_data.dict(),\n",
    "                \"crop_results\": crop_result_list,\n",
    "                \"result_data\": analysis.result_data\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    except HTTPException:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ë¶„ì„ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"ë¶„ì„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "print(\"âœ… Analysis API êµ¬í˜„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "server_start",
   "metadata": {},
   "source": [
    "## ğŸ–¥ï¸ 10. ì„œë²„ ì‹œì‘ ë° í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "server_startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„œë²„ ì‹œì‘ (ë¹„ë™ê¸°)\n",
    "import threading\n",
    "import uvicorn\n",
    "\n",
    "def start_server():\n",
    "    \"\"\"ì„œë²„ ì‹œì‘ í•¨ìˆ˜\"\"\"\n",
    "    uvicorn.run(\n",
    "        app,\n",
    "        host=settings.HOST,\n",
    "        port=settings.PORT,\n",
    "        log_level=\"info\"\n",
    "    )\n",
    "\n",
    "# ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì„œë²„ ì‹œì‘\n",
    "server_thread = threading.Thread(target=start_server, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "print(f\"ğŸš€ ì„œë²„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"ğŸ“ URL: http://{settings.HOST}:{settings.PORT}\")\n",
    "print(f\"ğŸ“– API ë¬¸ì„œ: http://{settings.HOST}:{settings.PORT}/api/docs\")\n",
    "print(f\"ğŸ” í—¬ìŠ¤ ì²´í¬: http://{settings.HOST}:{settings.PORT}/health\")\n",
    "\n",
    "# ì ì‹œ ëŒ€ê¸° í›„ í—¬ìŠ¤ ì²´í¬\n",
    "import time\n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    import requests\n",
    "    response = requests.get(f\"http://{settings.HOST}:{settings.PORT}/health\")\n",
    "    if response.status_code == 200:\n",
    "        print(\"âœ… ì„œë²„ í—¬ìŠ¤ ì²´í¬ ì„±ê³µ!\")\n",
    "        print(f\"ì‘ë‹µ: {response.json()}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ í—¬ìŠ¤ ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    print(\"ì„œë²„ê°€ ì•„ì§ ì‹œì‘ ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_section",
   "metadata": {},
   "source": [
    "## ğŸ§ª 11. API í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "api_testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤\n",
    "import requests\n",
    "import json\n",
    "\n",
    "BASE_URL = f\"http://{settings.HOST}:{settings.PORT}/api/v1\"\n",
    "\n",
    "def test_health_check():\n",
    "    \"\"\"í—¬ìŠ¤ ì²´í¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"http://{settings.HOST}:{settings.PORT}/health\")\n",
    "        print(f\"ğŸ“‹ í—¬ìŠ¤ ì²´í¬: {response.status_code}\")\n",
    "        if response.status_code == 200:\n",
    "            print(json.dumps(response.json(), indent=2, ensure_ascii=False))\n",
    "        return response.status_code == 200\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_image_list():\n",
    "    \"\"\"ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/images\")\n",
    "        print(f\"ğŸ“¸ ì´ë¯¸ì§€ ëª©ë¡: {response.status_code}\")\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"ì‘ë‹µ: {json.dumps(data, indent=2, ensure_ascii=False)}\")\n",
    "        return response.status_code == 200\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_analysis_list():\n",
    "    \"\"\"ë¶„ì„ ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/analyses\")\n",
    "        print(f\"ğŸ”¬ ë¶„ì„ ëª©ë¡: {response.status_code}\")\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"ì‘ë‹µ: {json.dumps(data, indent=2, ensure_ascii=False)}\")\n",
    "        return response.status_code == 200\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë¶„ì„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸ§ª API í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "tests = [\n",
    "    (\"í—¬ìŠ¤ ì²´í¬\", test_health_check),\n",
    "    (\"ì´ë¯¸ì§€ ëª©ë¡\", test_image_list),\n",
    "    (\"ë¶„ì„ ëª©ë¡\", test_analysis_list)\n",
    "]\n",
    "\n",
    "results = []\n",
    "for test_name, test_func in tests:\n",
    "    print(f\"\\nğŸ” {test_name} í…ŒìŠ¤íŠ¸:\")\n",
    "    result = test_func()\n",
    "    results.append((test_name, result))\n",
    "    print(f\"ê²°ê³¼: {'âœ… ì„±ê³µ' if result else 'âŒ ì‹¤íŒ¨'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:\")\n",
    "for test_name, result in results:\n",
    "    print(f\"  {test_name}: {'âœ…' if result else 'âŒ'}\")\n",
    "\n",
    "success_count = sum(1 for _, result in results if result)\n",
    "print(f\"\\nì´ {len(results)}ê°œ í…ŒìŠ¤íŠ¸ ì¤‘ {success_count}ê°œ ì„±ê³µ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample_data",
   "metadata": {},
   "source": [
    "## ğŸ“Š 12. ìƒ˜í”Œ ë°ì´í„° ìƒì„± ë° í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_sample_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ì´ë¯¸ì§€ ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)\n",
    "def create_sample_image():\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±\"\"\"\n",
    "    try:\n",
    "        # ê°„ë‹¨í•œ ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±\n",
    "        import numpy as np\n",
    "        from PIL import Image as PILImage\n",
    "        \n",
    "        # 3ì±„ë„ RGB ì´ë¯¸ì§€ ìƒì„± (1000x1000)\n",
    "        width, height = 1000, 1000\n",
    "        \n",
    "        # ë†ì§€ë¥¼ ëª¨ë°©í•œ íŒ¨í„´ ìƒì„±\n",
    "        img_array = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        \n",
    "        # ë…¹ìƒ‰ ê³„ì—´ì˜ ë°°ê²½ (ë†ì§€)\n",
    "        img_array[:, :, 1] = 120  # ë…¹ìƒ‰ ì±„ë„\n",
    "        img_array[:, :, 0] = 60   # ë¹¨ê°„ìƒ‰ ì±„ë„\n",
    "        img_array[:, :, 2] = 40   # íŒŒë€ìƒ‰ ì±„ë„\n",
    "        \n",
    "        # ëª‡ ê°œì˜ ì‚¬ê°í˜• íŒ¨í„´ ì¶”ê°€ (ë†ì§€ êµ¬íš)\n",
    "        for i in range(5):\n",
    "            x1 = np.random.randint(0, width-200)\n",
    "            y1 = np.random.randint(0, height-200)\n",
    "            x2 = x1 + np.random.randint(100, 200)\n",
    "            y2 = y1 + np.random.randint(100, 200)\n",
    "            \n",
    "            # ë‹¤ë¥¸ ìƒ‰ìƒì˜ ì‘ë¬¼ êµ¬ì—­\n",
    "            color = np.random.randint(80, 160, 3)\n",
    "            img_array[y1:y2, x1:x2] = color\n",
    "        \n",
    "        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜\n",
    "        pil_image = PILImage.fromarray(img_array)\n",
    "        \n",
    "        # íŒŒì¼ë¡œ ì €ì¥\n",
    "        sample_path = Path(settings.UPLOAD_PATH) / \"sample_farm_image.png\"\n",
    "        pil_image.save(sample_path)\n",
    "        \n",
    "        print(f\"âœ… ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±: {sample_path}\")\n",
    "        return str(sample_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# ìƒ˜í”Œ Shapefile ìƒì„±\n",
    "def create_sample_shapefile():\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ Shapefile ìƒì„±\"\"\"\n",
    "    try:\n",
    "        from shapely.geometry import Polygon\n",
    "        import geopandas as gpd\n",
    "        \n",
    "        # ìƒ˜í”Œ ë†ì§€ ê²½ê³„ ìƒì„± (5ê°œ êµ¬íš)\n",
    "        polygons = []\n",
    "        pnus = []\n",
    "        \n",
    "        for i in range(5):\n",
    "            # ì„ì˜ì˜ ì‚¬ê°í˜• ê²½ê³„ ìƒì„±\n",
    "            x_base = 200000 + i * 500  # UTM-K ì¢Œí‘œê³„ ê¸°ì¤€\n",
    "            y_base = 400000 + i * 300\n",
    "            \n",
    "            polygon = Polygon([\n",
    "                (x_base, y_base),\n",
    "                (x_base + 400, y_base),\n",
    "                (x_base + 400, y_base + 300),\n",
    "                (x_base, y_base + 300),\n",
    "                (x_base, y_base)\n",
    "            ])\n",
    "            \n",
    "            polygons.append(polygon)\n",
    "            pnus.append(f\"4717000000{i:03d}0000{i:03d}\")\n",
    "        \n",
    "        # GeoDataFrame ìƒì„±\n",
    "        gdf = gpd.GeoDataFrame({\n",
    "            'PNU': pnus,\n",
    "            'AREA': [p.area for p in polygons],\n",
    "            'geometry': polygons\n",
    "        })\n",
    "        \n",
    "        # CRS ì„¤ì • (UTM-K)\n",
    "        gdf.crs = \"EPSG:5186\"\n",
    "        \n",
    "        # Shapefile ì €ì¥\n",
    "        shapefile_path = Path(settings.UPLOAD_PATH) / \"sample_parcels.shp\"\n",
    "        gdf.to_file(shapefile_path)\n",
    "        \n",
    "        print(f\"âœ… ìƒ˜í”Œ Shapefile ìƒì„±: {shapefile_path}\")\n",
    "        return str(shapefile_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ìƒ˜í”Œ Shapefile ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "print(\"ğŸ“Š ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘...\")\n",
    "sample_image_path = create_sample_image()\n",
    "sample_shapefile_path = create_sample_shapefile()\n",
    "\n",
    "if sample_image_path and sample_shapefile_path:\n",
    "    print(\"âœ… ëª¨ë“  ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ\")\n",
    "    print(f\"ğŸ–¼ï¸ ìƒ˜í”Œ ì´ë¯¸ì§€: {sample_image_path}\")\n",
    "    print(f\"ğŸ—ºï¸ ìƒ˜í”Œ Shapefile: {sample_shapefile_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ ì¼ë¶€ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì‹¤íŒ¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ 13. ê°œë°œ ì™„ë£Œ ìƒíƒœ ë° ë‹¤ìŒ ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "development_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°œë°œ ì™„ë£Œ ìƒíƒœ ì²´í¬\n",
    "def check_development_status():\n",
    "    \"\"\"ê°œë°œ ì™„ë£Œ ìƒíƒœ ì²´í¬\"\"\"\n",
    "    print(\"ğŸ” Nong-View ê°œë°œ ìƒíƒœ ì²´í¬\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” í™•ì¸\n",
    "    with SessionLocal() as db:\n",
    "        try:\n",
    "            user_count = db.query(User).count()\n",
    "            image_count = db.query(Image).count()\n",
    "            analysis_count = db.query(Analysis).count()\n",
    "            crop_count = db.query(CropResult).count()\n",
    "            \n",
    "            print(f\"ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ:\")\n",
    "            print(f\"  ğŸ‘¥ ì‚¬ìš©ì: {user_count}ëª…\")\n",
    "            print(f\"  ğŸ–¼ï¸ ì´ë¯¸ì§€: {image_count}ê°œ\")\n",
    "            print(f\"  ğŸ”¬ ë¶„ì„: {analysis_count}ê°œ\")\n",
    "            print(f\"  âœ‚ï¸ í¬ë¡­ ê²°ê³¼: {crop_count}ê°œ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "    directories = {\n",
    "        \"ì—…ë¡œë“œ\": settings.UPLOAD_PATH,\n",
    "        \"í¬ë¡­\": settings.CROP_PATH,\n",
    "        \"ë‚´ë³´ë‚´ê¸°\": settings.EXPORT_PATH,\n",
    "        \"ëª¨ë¸\": settings.MODEL_PATH\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸ“ ë””ë ‰í† ë¦¬ ìƒíƒœ:\")\n",
    "    for name, path in directories.items():\n",
    "        path_obj = Path(path)\n",
    "        exists = path_obj.exists()\n",
    "        file_count = len(list(path_obj.glob('*'))) if exists else 0\n",
    "        print(f\"  {name}: {'âœ…' if exists else 'âŒ'} ({file_count}ê°œ íŒŒì¼)\")\n",
    "    \n",
    "    # AI ëª¨ë¸ ìƒíƒœ í™•ì¸\n",
    "    print(f\"\\nğŸ¤– AI ëª¨ë¸ ìƒíƒœ:\")\n",
    "    for model_type in ai_engine.models:\n",
    "        print(f\"  {model_type}: âœ… ë¡œë“œë¨\")\n",
    "    \n",
    "    # ì™„ì„±ë„ ê³„ì‚°\n",
    "    completed_features = [\n",
    "        \"ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸\",\n",
    "        \"POD1 ë°ì´í„° ìˆ˜ì§‘\", \n",
    "        \"POD2 í¬ë¡œí•‘\",\n",
    "        \"POD4 AI ì¶”ë¡ \",\n",
    "        \"Images API\",\n",
    "        \"Analysis API\",\n",
    "        \"API í…ŒìŠ¤íŠ¸\"\n",
    "    ]\n",
    "    \n",
    "    remaining_features = [\n",
    "        \"POD3 íƒ€ì¼ë§\",\n",
    "        \"POD5 ë³‘í•©\", \n",
    "        \"POD6 GPKG ë‚´ë³´ë‚´ê¸°\",\n",
    "        \"Statistics API\",\n",
    "        \"ì¸ì¦ ì‹œìŠ¤í…œ\",\n",
    "        \"í”„ë¡œë•ì…˜ ë°°í¬\"\n",
    "    ]\n",
    "    \n",
    "    total_features = len(completed_features) + len(remaining_features)\n",
    "    completion_rate = (len(completed_features) / total_features) * 100\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ ì „ì²´ ì™„ì„±ë„: {completion_rate:.1f}%\")\n",
    "    print(f\"âœ… ì™„ì„±ëœ ê¸°ëŠ¥ ({len(completed_features)}ê°œ):\")\n",
    "    for feature in completed_features:\n",
    "        print(f\"  - {feature}\")\n",
    "    \n",
    "    print(f\"\\nâ³ ë‚¨ì€ ê¸°ëŠ¥ ({len(remaining_features)}ê°œ):\")\n",
    "    for feature in remaining_features:\n",
    "        print(f\"  - {feature}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ë‹¤ìŒ ê°œë°œ ìš°ì„ ìˆœìœ„:\")\n",
    "    next_steps = [\n",
    "        \"1. POD3 íƒ€ì¼ë§ ì‹œìŠ¤í…œ í†µí•©\",\n",
    "        \"2. POD5 ê²°ê³¼ ë³‘í•© ì—”ì§„ í†µí•©\", \n",
    "        \"3. POD6 GPKG ë‚´ë³´ë‚´ê¸° í†µí•©\",\n",
    "        \"4. Statistics API êµ¬í˜„\",\n",
    "        \"5. ì¢…í•© í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê¹…\",\n",
    "        \"6. í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„\"\n",
    "    ]\n",
    "    \n",
    "    for step in next_steps:\n",
    "        print(f\"  {step}\")\n",
    "\n",
    "# ìƒíƒœ ì²´í¬ ì‹¤í–‰\n",
    "check_development_status()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ‰ Nong-View v1.0 í†µí•© ê°œë°œ ë…¸íŠ¸ë¶ ì™„ì„±!\")\n",
    "print(\"ğŸ“ ì´ ë…¸íŠ¸ë¶ì—ì„œ êµ¬í˜„ëœ ë‚´ìš©:\")\n",
    "print(\"  - ì™„ì „í•œ ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ (SQLAlchemy)\")\n",
    "print(\"  - POD ëª¨ë“ˆ í†µí•© (ë°ì´í„° ìˆ˜ì§‘, í¬ë¡œí•‘, AI ì¶”ë¡ )\")\n",
    "print(\"  - RESTful API (ì´ë¯¸ì§€ ê´€ë¦¬, ë¶„ì„ ì‹¤í–‰)\")\n",
    "print(\"  - ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì²˜ë¦¬\")\n",
    "print(\"  - API í…ŒìŠ¤íŠ¸ ë° ìƒ˜í”Œ ë°ì´í„°\")\n",
    "print(\"\\nğŸš€ ì„œë²„ URL: http://127.0.0.1:8000/api/docs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}